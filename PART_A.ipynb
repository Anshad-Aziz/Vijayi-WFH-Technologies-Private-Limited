{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy pandas nltk"
      ],
      "metadata": {
        "id": "yL0QrbS45JF3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ff11bd-5c07-4e32-b816-625cf8e4c99b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.7.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zMJSATrH40ZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddaf61fa-0458-48bd-8cea-9ed867195329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from spacy import displacy\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "# Load Spacy's NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function for text preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text\n",
        "df=pd.read_csv(\"task_dataset_100.csv\")\n",
        "# Apply preprocessing\n",
        "df[\"Cleaned Text\"] = df[\"Raw Text\"].apply(preprocess_text)\n",
        "\n",
        "# Save processed data\n",
        "df.to_csv(\"processed_task_dataset.csv\", index=False)\n",
        "print(\"✅ Preprocessing done! Saved as 'processed_task_dataset.csv'.\")\n"
      ],
      "metadata": {
        "id": "2b3F0dIY5KHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a01a1712-fbe0-43d9-ca0e-7117f28d1e8e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Preprocessing done! Saved as 'processed_task_dataset.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_kFlbNN-dBB",
        "outputId": "01a79ec1-0cd7-4f2c-85c7-5adc6356df78"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define a list of common action verbs that indicate a task\n",
        "action_verbs = [\"buy\", \"submit\", \"clean\", \"finish\", \"schedule\", \"send\", \"prepare\", \"book\", \"review\", \"fix\"]\n",
        "\n",
        "# Function to identify sentences that contain a task\n",
        "def extract_tasks(text):\n",
        "    sentences = sent_tokenize(text)  # Tokenize into sentences\n",
        "    task_sentences = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        words = sentence.lower().split()\n",
        "\n",
        "        # Rule: Check if an action verb is present\n",
        "        if any(verb in words for verb in action_verbs):\n",
        "            task_sentences.append(sentence)\n",
        "\n",
        "    return task_sentences if task_sentences else None\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"task_dataset_100.csv\")  # Ensure you have this CSV file in the same directory\n",
        "\n",
        "# Apply the function to extract tasks from the \"Raw Text\" column\n",
        "df[\"Extracted Task\"] = df[\"Raw Text\"].apply(extract_tasks)\n",
        "\n",
        "# Save the extracted tasks to a new CSV\n",
        "df.to_csv(\"extracted_tasks.csv\", index=False)\n",
        "print(\"✅ Task extraction complete! Saved as 'extracted_tasks.csv'.\")\n"
      ],
      "metadata": {
        "id": "rfcZ6vp-5KEQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74cf5ef-616f-4a90-eada-dbb4f983aa7e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Task extraction complete! Saved as 'extracted_tasks.csv'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define categories based on keywords\n",
        "categories = {\n",
        "    \"Shopping\": [\"buy\", \"order\"],\n",
        "    \"Work\": [\"submit\", \"prepare\", \"review\", \"complete\"],\n",
        "    \"Household\": [\"clean\", \"fix\", \"repair\"],\n",
        "    \"Meetings\": [\"schedule\", \"send\", \"arrange\"],\n",
        "    \"Personal\": [\"book\", \"call\"]\n",
        "}\n",
        "\n",
        "# Function to categorize a task\n",
        "def categorize_task(task):\n",
        "    if not task: return \"Other\"\n",
        "\n",
        "    for category, keywords in categories.items():\n",
        "        if any(keyword in task.lower() for keyword in keywords):\n",
        "            return category\n",
        "    return \"Other\"\n",
        "\n",
        "# Apply categorization\n",
        "df[\"Category\"] = df[\"Extracted Task\"].apply(lambda x: categorize_task(str(x)))\n",
        "\n",
        "# Save categorized tasks\n",
        "df.to_csv(\"categorized_tasks.csv\", index=False)\n",
        "print(\"✅ Task categorization complete! Saved as 'categorized_tasks.csv'.\")\n"
      ],
      "metadata": {
        "id": "VipboPuW5KA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27dddb96-97f4-448a-b5d3-c934ed1ea5d3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Task categorization complete! Saved as 'categorized_tasks.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract names and deadlines\n",
        "def extract_person_and_deadline(text):\n",
        "    doc = nlp(text)\n",
        "    person = None\n",
        "    deadline = None\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ == \"PERSON\":  # Extract person\n",
        "            person = ent.text\n",
        "        elif ent.label_ in [\"DATE\", \"TIME\"]:  # Extract deadline\n",
        "            deadline = ent.text\n",
        "\n",
        "    return person, deadline\n",
        "\n",
        "# Apply function to extract person and deadline\n",
        "df[\"Person\"], df[\"Deadline\"] = zip(*df[\"Raw Text\"].apply(extract_person_and_deadline))\n",
        "\n",
        "# Save extracted data\n",
        "df.to_csv(\"final_tasks.csv\", index=False)\n",
        "print(\"✅ Task extraction with people and deadlines complete! Saved as 'final_tasks.csv'.\")\n"
      ],
      "metadata": {
        "id": "0t_d0prw5J-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a887e23-ee4b-4301-af31-4a3fb68a4f0f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Task extraction with people and deadlines complete! Saved as 'final_tasks.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[[\"Raw Text\", \"Extracted Task\", \"Person\", \"Deadline\", \"Category\"]].head(10))\n"
      ],
      "metadata": {
        "id": "dG_j06yC5J7J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66f2acb-a562-4909-eef0-c1c427244356"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Raw Text  \\\n",
            "0  The manager assigned David to prepare the meet...   \n",
            "1  Daniel has to submit the tax documents by Apri...   \n",
            "2      Ava needs to clean the garden this afternoon.   \n",
            "3      Ava needs to clean the garden this afternoon.   \n",
            "4  Noah should prepare a presentation for the con...   \n",
            "5    Liam must schedule the meeting with the vendor.   \n",
            "6  Olivia should finalize the budget report befor...   \n",
            "7             John must submit the report by Monday.   \n",
            "8  Noah should prepare a presentation for the con...   \n",
            "9  The manager assigned David to prepare the meet...   \n",
            "\n",
            "                                      Extracted Task Person        Deadline  \\\n",
            "0  [The manager assigned David to prepare the mee...  David            None   \n",
            "1  [Daniel has to submit the tax documents by Apr...   None        April 15   \n",
            "2    [Ava needs to clean the garden this afternoon.]   None  this afternoon   \n",
            "3    [Ava needs to clean the garden this afternoon.]   None  this afternoon   \n",
            "4  [Noah should prepare a presentation for the co...   None            None   \n",
            "5  [Liam must schedule the meeting with the vendor.]   Liam            None   \n",
            "6                                               None   None     next Monday   \n",
            "7           [John must submit the report by Monday.]   John          Monday   \n",
            "8  [Noah should prepare a presentation for the co...   None            None   \n",
            "9  [The manager assigned David to prepare the mee...  David            None   \n",
            "\n",
            "    Category  \n",
            "0       Work  \n",
            "1       Work  \n",
            "2  Household  \n",
            "3  Household  \n",
            "4       Work  \n",
            "5   Meetings  \n",
            "6      Other  \n",
            "7       Work  \n",
            "8       Work  \n",
            "9       Work  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Na_mzof5J4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SwuV5XPf5Jxo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}